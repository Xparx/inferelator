{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tchourine, K., Vogel, C., and Bonneau, R. (2018)\n",
    "# Condition-Specific Modeling of Biophysical Parameters Advances Inference of Regulatory Networks\n",
    "# Cell Reports 23, 376â€“388. https://doi.org/10.1016/j.celrep.2018.03.048\n",
    "\n",
    "# Load modules\n",
    "\n",
    "from inferelator import utils\n",
    "from inferelator.distributed.inferelator_mp import MPControl\n",
    "from inferelator import workflow\n",
    "\n",
    "# Set verbosity level to \"Talky\"\n",
    "utils.Debug.set_verbose_level(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the location of the input data and the desired location of the output files\n",
    "\n",
    "DATA_DIR = '../data/tchourine'\n",
    "OUTPUT_DIR = '~/tchourine_2018/'\n",
    "\n",
    "# The expression and gene metadata are separated into clusters based on the biclustering approach in the\n",
    "# published manuscript. \n",
    "\n",
    "EXPRESSION_FILE_NAME = ['expr_clust1.tsv.gz', 'expr_clust2.tsv.gz', 'expr_clust3.tsv.gz', 'expr_clust4.tsv.gz']\n",
    "METADATA_FILE_NAME = ['meta_clust1.tsv.gz', 'meta_clust2.tsv.gz', 'meta_clust3.tsv.gz', 'meta_clust4.tsv.gz']\n",
    "GENE_CLUSTER_FILE = ['genes_clust1.tsv.gz', 'genes_clust2.tsv.gz', 'genes_clust3.tsv.gz', 'genes_clust4.tsv.gz', 'genes_clust5.tsv.gz']\n",
    "GENE_METADATA_FILE_NAME = 'orfs.tsv'\n",
    "TF_LIST_FILE_NAME = 'tf_names_restrict.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new workflow class to handle crossvalidation of the Tau parameter for each individual cluster\n",
    "\n",
    "from inferelator import amusr_workflow\n",
    "from inferelator import utils\n",
    "from inferelator.postprocessing.results_processor import ResultsProcessor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class InferecladrRP(ResultsProcessor):\n",
    "\n",
    "    def summarize_network(self, cluster_gene_list, gold_standard, priors):\n",
    "\n",
    "        cluster_aupr = []\n",
    "        for cluster_genes in cluster_gene_list:\n",
    "            cluster_gold = gold_standard.reindex(gold_standard.index.intersection(cluster_genes))\n",
    "            cluster_priors = priors.reindex(priors.index.intersection(cluster_genes))\n",
    "            cluster_aupr.append(super(InferecladrRP, self).summarize_network(None, cluster_gold, cluster_priors))\n",
    "\n",
    "        return cluster_aupr\n",
    "\n",
    "\n",
    "def patch_puppet(obj):\n",
    "    \"\"\"\n",
    "    Fix the emit results in a puppet for the inferecladr\n",
    "    :param obj: PuppetWorkflow\n",
    "    \"\"\"\n",
    "\n",
    "    import types\n",
    "\n",
    "    def emit_results(self, betas, rescaled_betas, gold_standard, priors):\n",
    "        if self.is_master():\n",
    "            rp = InferecladrRP(betas, rescaled_betas, filter_method=self.gold_standard_filter_method)\n",
    "            self.aupr = rp.summarize_network(self.cluster_gene_list, gold_standard, priors)\n",
    "            return self.aupr\n",
    "\n",
    "    obj.emit_results = types.MethodType(emit_results, obj)\n",
    "\n",
    "\n",
    "class InferecladrWorkflow(amusr_workflow.MultitaskLearningWorkflow):\n",
    "    seeds = None\n",
    "    auprs = None\n",
    "    taus = None\n",
    "\n",
    "    # Gene cluster lists\n",
    "    gene_cluster_list_file = None\n",
    "    cluster_gene_list = None\n",
    "\n",
    "    # What type of modeling used to crossvalidate taus\n",
    "    cv_regression_type = \"bbsr\"\n",
    "    cv_workflow_type = \"tfa\"\n",
    "\n",
    "    final_network_file = \"network.tsv\"\n",
    "    final_pr_curve = \"pr_curve.pdf\"\n",
    "\n",
    "    def get_data(self):\n",
    "        # Load the cluster lists and then call the normal get_data\n",
    "        self.read_gene_cluster_lists()\n",
    "        super(InferecladrWorkflow, self).get_data()\n",
    "\n",
    "    def startup_finish(self):\n",
    "        # Handle data preprocessing in the individual CV runs\n",
    "        pass\n",
    "\n",
    "    def read_gene_cluster_lists(self, file=None):\n",
    "        \"\"\"\n",
    "        Load a list of gene list files or break a single dataframe with clusters as the second column\n",
    "        into a list of genes\n",
    "        \"\"\"\n",
    "\n",
    "        file = file if file is not None else self.gene_cluster_list_file\n",
    "\n",
    "        if isinstance(file, list):\n",
    "            self.cluster_gene_list = [self.input_dataframe(cluster_genes) for cluster_genes in file]\n",
    "        else:\n",
    "            cluster_df = self.input_dataframe(file, index_col=None, header=None, names=(\"gene\", \"cluster\"))\n",
    "            clusters = cluster_df.loc[:, \"cluster\"].sort_values().unique()\n",
    "            self.cluster_gene_list = [cluster_df.loc[cluster_df[\"cluster\"] == gene_clust, \"gene\"].tolist()\n",
    "                                      for gene_clust in clusters]\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Execute workflow, after all configuration.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the random seed (for bootstrap selection)\n",
    "        np.random.seed(self.random_seed)\n",
    "\n",
    "        # Call the startup workflow\n",
    "        self.startup()\n",
    "\n",
    "        # Crossvalidate clusters for tau\n",
    "        self.crossvalidate_taus()\n",
    "        self.tau = self.find_optimal_taus()\n",
    "\n",
    "        # Pile up cluster data\n",
    "        self.pileup_clusters()\n",
    "\n",
    "        # Reset the workflow for the final regression\n",
    "        self.cv_result_processor_type = ResultsProcessor\n",
    "        final_task = self.new_puppet(self.expression_matrix, self.meta_data,\n",
    "                                     gold_standard=self.gold_standard, priors_data=self.priors_data)\n",
    "        final_task.network_file_name = self.final_network_file\n",
    "        final_task.pr_curve_file_name = self.final_pr_curve\n",
    "        final_task.write_network = True\n",
    "        final_task.output_dir = self.output_dir\n",
    "        final_task.run()\n",
    "\n",
    "        return final_task.network\n",
    "\n",
    "    def pileup_clusters(self):\n",
    "        \"\"\"\n",
    "        Glue together the cluster data into one large data set\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.expression_matrix = pd.concat(self.expression_matrix, axis=1)\n",
    "        self.meta_data = pd.concat(self.meta_data, axis=0)\n",
    "\n",
    "    def crossvalidate_taus(self):\n",
    "        \"\"\"\n",
    "        Run a regression (2-fold CV) on each expression cluster with every random seed and every possible tau\n",
    "        Set self.auprs[gene_cluster][tau] to a list of AUPR results for that gene cluster at a given tau\n",
    "        \"\"\"\n",
    "        self.auprs = {k: {t: [] for t in self.taus} for k in range(len(self.expression_matrix))}\n",
    "        for expr, meta in zip(self.expression_matrix, self.meta_data):\n",
    "            assert expr.shape[1] == meta.shape[0]\n",
    "            for tau in self.taus:\n",
    "                for seed in self.seeds:\n",
    "                    task = self.new_puppet(expr, meta, seed=seed)\n",
    "                    task.split_gold_standard_for_crossvalidation = True\n",
    "                    task.cv_split_ratio = 0.5\n",
    "                    task.tau = tau\n",
    "                    task.cluster_gene_list = self.cluster_gene_list\n",
    "                    patch_puppet(task)\n",
    "                    task.run()\n",
    "                    for gene_cluster in range(len(self.cluster_gene_list)):\n",
    "                        self.auprs[gene_cluster][tau].append(task.aupr[gene_cluster])\n",
    "\n",
    "    def find_optimal_taus(self):\n",
    "\n",
    "        n_clusters = len(self.cluster_gene_list)\n",
    "\n",
    "        # Find the median AUPR for each gene_cluster & tau combination\n",
    "        median_by_seed = {cluster: {tau: np.median(self.auprs[cluster][tau])\n",
    "                                    for tau in self.tau}\n",
    "                          for cluster in range(n_clusters) }\n",
    "\n",
    "        # Find the TAU which maximizes median AUPR for each gene cluster\n",
    "        best_aupr = {k: max(median_by_seed[k], key=median_by_seed[k].get) for k in range(n_clusters)}\n",
    "\n",
    "        taus = []\n",
    "        for gene_clust, genes in enumerate(self.cluster_gene_list):\n",
    "            utils.Debug.vprint(\"Optimal Tau={tau} for cluster {cl}\".format(tau=best_aupr[gene_clust], cl=gene_clust))\n",
    "            taus.extend([best_aupr[gene_clust]] * len(genes))\n",
    "        return taus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start Multiprocessing Engine\n",
    "# Default to a single computer. Setting up a cluster is left as an exercise to the reader.\n",
    "\n",
    "n_cores_dask = 200\n",
    "activate_path = '~/.local/anaconda3/bin/activate'\n",
    "dask_engine = False\n",
    "\n",
    "n_cores_local = 3\n",
    "local_engine = True\n",
    "\n",
    "# The if __name__ is __main__ pragma protects against runaway multiprocessing\n",
    "# Dask requires a slurm controller in an HPC environment.\n",
    "# The conda or venv activate script is necessary to set the worker environment\n",
    "# This code does NOT set the environment for the current process, only for workers\n",
    "\n",
    "if __name__ == '__main__' and dask_engine:\n",
    "    MPControl.set_multiprocess_engine(\"dask-cluster\")\n",
    "    MPControl.client.minimum_cores = n_cores_dask\n",
    "    MPControl.client.maximum_cores = n_cores_dask\n",
    "    MPControl.client.walltime = '48:00:00'\n",
    "    MPControl.client.add_worker_env_line('module load slurm')\n",
    "    MPControl.client.add_worker_env_line('module load gcc/8.3.0')\n",
    "    MPControl.client.add_worker_env_line('source ' + activate_path)\n",
    "    MPControl.client.cluster_controller_options.append(\"-p ccb\")\n",
    "    MPControl.connect()\n",
    "    \n",
    "# Multiprocessing uses the pathos implementation of multiprocessing (with dill instead of cPickle)\n",
    "# This is suited for a single computer, but will likely be too slow for the example here\n",
    "    \n",
    "if __name__ == '__main__' and local_engine:\n",
    "    MPControl.set_multiprocess_engine(\"multiprocessing\")\n",
    "    MPControl.client.processes = n_cores_local\n",
    "    MPControl.connect()\n",
    "\n",
    "# Set up the workflow\n",
    "\n",
    "worker = workflow.inferelator_workflow(regression=\"bbsr\", workflow=InferecladrWorkflow)\n",
    "worker.input_dir = DATA_DIR\n",
    "worker.output_dir = OUTPUT_DIR\n",
    "worker.expression_matrix_file = EXPRESSION_FILE_NAME\n",
    "worker.meta_data_file = METADATA_FILE_NAME\n",
    "worker.gene_metadata_file = GENE_METADATA_FILE_NAME\n",
    "worker.tf_names_file = TF_LIST_FILE_NAME\n",
    "worker.gene_cluster_list_file = GENE_CLUSTER_FILE\n",
    "\n",
    "# Set the seeding and the potential Tau values for crossvalidation\n",
    "\n",
    "worker.seeds = range(42,62)\n",
    "worker.taus = [0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 200, 250]\n",
    "\n",
    "final_network = worker.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
